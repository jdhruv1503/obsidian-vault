
![[Clustering or unsupervised learning]]

## Classification problems

### Overview

We have to find a [[Hypothesis]] h in [[Hypothesis space]] H such that h(x) = c(x) for all x in D.

**Inductive learning hypothesis**: Any hypothesis approximating c over training samples will also approximate c over all samples.

### Find-S algorithm

#### General to specific ordering of hypotheses.

Definition: Let hj and hk be boolean-valued functions defined over X. Then hj is
moregeneral-than-or-equal-to hk (written hj 2, h k ) if and only if

![[Pasted image 20240812040516.png]]

This can be visualised using [[Hasse diagram]]

![[Hasse diagram]]

 One way is to begin
with the most specific possible hypothesis in H, then generalize this hypothesis
each time it fails to cover an observed positive training example. (We say that
a hypothesis "covers" a positive example if it correctly classifies the example as
positive.)

This is the **Find-S algo**:

![[Pasted image 20240812040737.png]]

Because we are moving from **the most specific** hypothesis and assume that $c$ exists in $H$, we never need to look at negative examples!! $c$ will always be less or equal specificity as compared to our current hypothesis, and so if te